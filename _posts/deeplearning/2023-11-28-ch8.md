# Optimization for Training Deep Models

## Chanllenges in neural network optimization

### Ill-conditioning

As discussed in ch4, ill-conditioned Hessian matrix can cause difficulty in choosing step size.

A method to determine wether ill-conditioning is detrimental is to monitor the terms $\boldsymbol{g}^{\mathsf{T}} \boldsymbol{g}$ and $\boldsymbol{g}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{g}$.
In the case of ill-conditioning, it usually appears that the squared gradient norm does not shrink significantly but the $\boldsymbol{g}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{g}$ grows by more than an order of maginitude.

### Local Minima

Deep models generally have a large number of local minima.

A model is said to be identifiable if a sufficiently large data set can rule out all but one set of parameters.
Models with latent variables are often not identifiable. For instance, we can exchange the components along with the latent variable of a mixture model without comprising the equivalence.
For neural network, a common source of non-identifiability comes from the weight space symmetry.

Local minima with high cost can be problematic for gradient-based algorithms. 
A test that can rule out the local minima as the problem is to plot the norm of the gradient over time.

### Plateaus, saddle points and other flat regions



## Basic algorithms

### Stochastic gradient descent

The SGD is given as follows

![](/assets/images/deeplearning/alg-8.1.png)

Because SGD introduces a source of noise by randomly sampling the training data, the gradient may not vanish even at the minimum.
The learning rate must be carefully chosen. A sufficient condition to guarantee convergence is 

$$
\begin{align*}
\sum_{k=1}^\infty \epsilon_k &= \infty \\
\sum_{k=1}^\infty \epsilon_k^2 &< \infty \\
\end{align*}
$$

In practice, it is common to decay the learning rate linearly until iteration $\tau$:

$$
\epsilon_k = (1 - \alpha) \epsilon_0 + \alpha \epsilon_{\tau}
$$

where $\alpha = k/\tau$. After iteration $\tau$, the learning rate is left constant.

Usually the learning rate is chosen by monitoring the objective function as function of time.
$\tau$ may be set to the number of iterations required to pass through the training set a few hundred times.
$\epsilon\_\tau$ is set tot roughly 1% of the $\epsilon\_0$.
$\epsilon\_0$ is set to some value higher than the learning rate that yeilds best performance after the first hundreds of iterations.

An advantage of SGD is that it does not require evaluation of the whole dataset to begin learning.
For large datasets, the convergence criterion may be met before all training data points are processed.

### Momentum

The momentum method is designed to tackle ill-conditioning Hessian and noisy gradient.

The update rule is given by

$$
\begin{align*}
\boldsymbol{v} &\leftarrow \alpha \boldsymbol{v}
- \epsilon \nabla_{\boldsymbol{\theta}} \left( \frac{1}{m} L(\boldsymbol{f}(\boldsymbol{x}^{(i)}, \boldsymbol{\theta}), \boldsymbol{y}^{(i)}) \right)  \\
\boldsymbol{\theta} &\leftarrow \boldsymbol{\theta} + \boldsymbol{v}
\end{align*}
$$

where hyperparameter $\alpha \in [0, 1]$. Large $\alpha$ relative to $\epsilon$ slow down the decaying of the past gradients.

The algorithm is given by

![](/assets/images/deeplearning/alg-8.2.png)

The velocity $\boldsymbol{v}$ can regarded as the momentum with unit mass and $\nabla\_{\boldsymbol{\theta}} \left( \frac{1}{m} L(\boldsymbol{f}(\boldsymbol{x}^{(i)}, \boldsymbol{\theta}), \boldsymbol{y}^{(i)}) \right)$ as the impulse with unit time.

We can gain some insight by first considering the case where gradient is constant $\boldsymbol{g}$. Then we have

$$
\begin{align*}
\boldsymbol{v}_{k} &= \alpha \boldsymbol{v}_{k-1} - \epsilon \boldsymbol{g} \\
&= \alpha^{k} \boldsymbol{v}_{0} - \epsilon \boldsymbol{g} \left( 1 + \alpha + \cdots + \alpha^{k-1} \right) \\
&= \alpha^{k} \boldsymbol{v}_{0} - \epsilon \boldsymbol{g} \left( \frac{1 - \alpha^k}{1 - \alpha}\right)
\end{align*}
$$

The $\alpha$ has the effect of a force proportional to $- \boldsymbol{v}(t)$, which corresponds to viscous drag.
In the limit $k \rightarrow \infty$, we obtain the terminal velocity 

$$
\frac{\epsilon \| \boldsymbol{g} \|}{1 - \alpha}
$$

If the initial velocity is taken to be non-zero and $\boldsymbol{g}$ to be zero

$$
\boldsymbol{v}_{k} = \alpha^{k} \boldsymbol{v}_{0}
$$


### Nesterov momentum

Nestrov momentum is a variant of momentum method in which the gradient is evaluated after the current velocity is applied.
The update rule is

$$ 
\begin{align*}
\boldsymbol{v} &\leftarrow \alpha \boldsymbol{v}
- \epsilon \nabla_{\boldsymbol{\theta}} \left( \frac{1}{m} L(\boldsymbol{f}(\boldsymbol{x}^{(i)}, \boldsymbol{\theta} + \alpha \boldsymbol{v}), \boldsymbol{y}^{(i)}) \right)  \\
\boldsymbol{\theta} &\leftarrow \boldsymbol{\theta} + \boldsymbol{v}
\end{align*}
$$

In the convex batch optimization, it improves the convergence rate.

## Parameter initialization strategies
