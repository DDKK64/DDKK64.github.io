# Part I

## Ch2 Linear algebra

Tensors: an array with a variable number of axes.

Broadcast: $\boldsymbol{C} = \boldsymbol{A} + \boldsymbol{b}$ adds $\boldsymbol{b}$ to each row of $\boldsymbol{A}$.

### Norm

The $L^p$ norm of vector $\boldsymbol{x}$ is defined

$$
\| \boldsymbol{x} \|_p = \left( \sum_i |x_i|^p \right)^{1/p}
$$

where $p \in \mathbb{R}$ and $p \ge 1$.

$p=2$: Euclidean norm, which suffers from precision loss (underflow) when $\boldsymbol{x}$ is very small.

$L^1$ norm makes a distinction between zero and non zero values.

Norm of matrix - Frobenius norm:

$$
\| A \|_F = \sqrt{\sum_{i,j} A_{ij}^2} = \sqrt{\operatorname{Tr(\boldsymbol{A}^{\mathsf{T}} \boldsymbol{A})}}
$$

### Moore-Penrose Pseudoinverse

$$
\boldsymbol{A}^+ = \lim_{\alpha \rightarrow 0} (\boldsymbol{A}^{\mathsf{T}} \boldsymbol{A} + \alpha \boldsymbol{I}) \boldsymbol{A}^{\mathsf{T}}
$$

equivalent to the SVD formulation

$$
\boldsymbol{A}^+ = \boldsymbol{V}_r \boldsymbol{D}_r^{-1} \boldsymbol{U}_r^{\mathsf{T}}
$$

## Ch3 Probability and Information Theory

### Common probability distributions

The exponential distribution:

$$
p(x;\lambda) = \lambda \mathbf{1}_{x \ge 0} \exp( - \lambda x)
$$

where

$$
\mathbf{1}_{x \ge 0} = \begin{cases}
0, &\text{if }x < 0 \\
1, &\text{otherwise}
\end{cases}
$$

The Laplace distribution:

$$
\operatorname{Laplace} (x; \mu, \gamma) = \frac{1}{2 \gamma} \exp \left( - \frac{|x - \mu|}{\gamma} \right)
$$

The Dirac distribution:

$$
p(x) = \delta(x - \mu)
$$

where $\delta$ is the Dirac function.

The empirical distribution:

$$
\hat{p} (\boldsymbol{x}) = \frac{1}{m} \sum_{i=1}^m \delta(\boldsymbol{x} - \boldsymbol{x}^{(i)})
$$

which can be viewd as the distribution from which the training examples are drawn.
It assigns $1/m$ probability for each example in the training set.

For discrete variables, the empirical frequency can be used directly.

### Useful properties of common functions

Softplus: $\zeta (x) = \log (1 + \exp(x))$

## Ch4 Numerical computation

Overflow: numbers with large magnitude are approximated as $\infty$ or $-\infty$.

Underflow: numbers near zero are rounded to zero.

### Poor conditioning

The condition number of a matrix $\boldsymbol{A} \in \mathbb{R}^{n\times n }$ is given by

$$
\max_{i,j} \left| \frac{\lambda_i}{\lambda_j} \right|
$$

Consider the function $f(\boldsymbol{x}) = \boldsymbol{A}^{-1} \boldsymbol{x}$. When the condition number is large, the matrix inversion is sensitive to error in the input.

### Gradient-based optimization

The function we want to minimize or maximize is called the **objective function** or **criterion**. 
If the goal is minimizing it, it is also called **cost function**, **loss function** or **error function**.

Points with zero derivative are known as the **critical points** or **stationary points**.

The directional derivative of the function $f(\boldsymbol{x})$ in the direction of unit vector $\boldsymbol{u}$ is given by $\boldsymbol{u}^{\mathsf{T}} \nabla f(\boldsymbol{x})$,
which indicates that gradiant points to the direction in which $f$ increases the fastest.

The optimization method that decreases objective by moving in the direction of the negative gradient is knwon as the **steepest descent** or **gradient descent**.
The algorithm proposes a new point using

$$
\boldsymbol{x}^\prime = \boldsymbol{x} - \epsilon \nabla_{\boldsymbol{x}} f(\boldsymbol{x})
$$

where $\epsilon$ is the learning rate.
The **linear search** strategy chooses $\epsilon$ from a several values so that $f(\boldsymbol{x} - \epsilon \nabla\_{\boldsymbol{x}} f(\boldsymbol{x}))$ takes the smallest value.

Another strategy involves the second derivative. Consider the taylor expansion at the current point $\boldsymbol{x}^{(0)}$

$$
f(\boldsymbol{x}^{(0)} - \epsilon \boldsymbol{g}) \approx f(\boldsymbol{x}^{(0)})
- \epsilon \boldsymbol{g}^{\mathsf{T}} \boldsymbol{g}
+ \frac{1}{2} \epsilon^2 \boldsymbol{g}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{g}
$$

where $\boldsymbol{g}$, $\boldsymbol{H}$ is the gradient and the Hessian at $\boldsymbol{x}^{(0)}$ respectively.

If $\boldsymbol{g}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{g}$ is positive and $f$ can be approximated well by the quadratic form, solving for the optimal step with respect to $\epsilon$ gives

$$
\epsilon^\ast = \frac{\boldsymbol{g}^{\mathsf{T}} \boldsymbol{g}}{\boldsymbol{g}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{g}}
$$

Let $\boldsymbol{d} = \frac{\boldsymbol{g}}{\\| \boldsymbol{g} \\|}$. We have

$$
\epsilon^\ast = \frac{1}{\boldsymbol{d}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{d}}
$$

where $\boldsymbol{d}^{\mathsf{T}} \boldsymbol{H} \boldsymbol{d}$ is the second derivative at direction $\boldsymbol{d}$.

When the Hessian has a poor condition number, the gradient descent may perform poorly.
The derivative increases drastically in some direction and slowly in some other.
However, the gradient descent is unaware of such change, which makes it problematic to choose a proper step size.
So the step should be small enough not to overstep and going uphill in the direction with strong curvature. Small step consequently gives slow pregression of optimization.

![](/assets/images/deeplearning/fig-4.6.png)

One of methods exploiting the curvature is known as the **Newton's method**.
It is attracted to saddle points.

## Ch5 Machine Learning basics

### Leaning algorithms

Machine learning: a program learns from experience $E$, improves the performance measured by $P$ on specifix task $T$.

An **example** is a vector of features measured from some process.

#### The task $T$

- Classification
- Classification with missing inputs: some features are missing in the input vector
- Regression
- Transcription: turning unstructured data into desired textual form. E.g. optical charater recognition, speech recognition.
- Machine translation
- Structured output: parsing structured data.
- Anomaly detection: find atypical events/objects from the data set. E.g. financial fraud detection.
- Synthesis and sampling: generate new examples similar to the ones in the training set. E.g. AIGC.
- Imputation of missing values: predict values of missing feature in the example.
- Denoising: predict the original clean example from the corrupted example.
- Density estimation or probability mass function estimation

#### The performance measure $P$

The measure criterion is application specific. The error rate can be used for classification.
The measure for density estimation is difficult to choose.

We usually evaluate the performance on the test set.

#### The experience $E$

The dataset.

### Capacity, overfitting and underfitting

The performance on previously unseen data is called the **generalization**.

The error measured on the training set is called the **training error**.

The error measured on the new data is called the **generalization error**, which is the final objective we want to reduce.

The **capacity** of a model is the ability of a model to learn a variety of functions.
Low capacity usually results in underfitting. High capcity may lead to overfitting by simply memorizing the training set.

The **representational capacity** of model indicate the set of functions a model can represent.

However, due to limitations such as the inability of the optimization algorithm, the **effective capacity** may be less the representational capacity.

