---
layout: posts
title: '6.824 - Map reduce'
---
# MapReduce

Paper: MapReduce: Simplified Data Processing on Large Clusters

MR manages distribution of computations on large data sets. E.g. search index build, sort, web structure analysis, grep.

- User-firendly: easy to program with
- High degree of parallelism

## Programming model

map: (k1, v1) &rarr; list (k2, v2)

reduce: (k2, list (v2)) &rarr; list(v3)

## Execution Overview

![](/assets/images/theses/mr-fig1.png)

1. Input files (in GFS) are (beforehand) split into *M* pieces of typically 16MB to 64MB, from which kv pairs are parsed.

2. Many copies of the user program are started on a cluster of machines. One instance becomes the master, and the rest become workers. There are M map tasks and R reduce tasks to be assigned to workers by the master.

3. A map tasks parse kv pairs from a split, and passes each pair into the user defined map function. The resulting intermediate kv pairs are bufferd in the memory.

4. Periodically, the buffered kv pairs are written to the local disks, parititioned into R regions by paritioning function. The location of regions are passed back to the master, and forwarded to the reduce worker by the master.

5. When a reduce worker is notified by the master of locations of these paris, it reads the data by remote procedure call and groups all the intermediate pairs with the same key. If the partition is too large to fit in the memory, an external sort is used.

6. A set of values of the same intermediate key are passed to the reduce function, and the output of reduce function is appended to a final output file of this reduce partition.

## Example: Word count

```
map(String key, String value):
    // key: document name
    // value: document contents
    for each word w in value:
        EmitIntermediate(w, "1");

reduce(String key, Iterator values):
    // key: a word
    // values: a list of counts
    int result = 0;
    for each v in values:
        result += ParseInt(v);
        Emit(AsString(result));
```

## Example: Sort

## Master Data Structure

Master stores:

- tasks status: idle, in-progress or completed.
- worker identity for non-idle tasks

The locations of intermediate file regions are pushed *incrementally* to reduce tasks.

## Fault Tolerace

### worker failure

Failed map/reduce tasks are marked as idle and rescheduled.

Completed map tasks on failed workers are reset to idle and rescheduled, since the local intermediate data may be lost.

Commpleted reduce tasks do not need rescheduling, since the outputs are replicated in GFS.

#### Master Failure

Abort the entire mapreduce execution.

Periodic checkpoints can be utilized to alleviate retry cost.

#### Semantics in the Presence of Failures

For map: completion messages for an already completed map tasks are ignored by the master.

For reduce: atomic rename for output files in GFS.

### Localilty

To reduce network traffic, map tasks are scheduled on/near the machines where the input data blocks reside.

> How about the locality of reduce tasks?

### Task Granularity

M usually corresponsds to the number of input file chunks.

R is set to a small multiple of the number of workers.

$O(M+R)$ time for task scheduling.

$O(M*R)$ space for task states.

### Backup Tasks

*Stragglers*: tasks that are slowed down by some reason: resource competition, bad disk, bugs...

When mapreduce operation is close to completion, backup tasks are scheduled for stragglers.

## Refinements and Customizations

- User-specified partitioning function
- Within a given partition, the intermediate kv pairs are delivered to reduce function in key increasing order.
- Combiner function: does partial data merging locally after map tasks. E.g. merge all `(word, 1)` pairs.
- Support interfaces that read/write from/to sources other than GFS.
- Capture worker crash and skip bad records
- Local mr library for debugging
- Master runs an HTTP server to display status
- Builtin counter class that avoids double counting

## Performance

Data transfer rate shows progress.

![](/assets/images/theses/mr-fig3.png)