---
title: 'PRML Supplement - Lagrange multiplier'
layout: posts
---
# Lagrange multiplier

Consider a problem of maximizing the function $f(\mathbf{x}) = 0$ under the constraint $g(\mathbf{x})=0$.

Note that $g(\mathbf{x}) = 0$ corresponds to a $(D-1)$-demensional surface in the space of $\mathbf{x}$. 

The gradient $\nabla g(\mathbf{x})$ is orthogonal to the surface. This can be shown by taking another point $\mathbf{x}+\boldsymbol{\epsilon}$ lies in the surface such that $g(\mathbf{x}+\boldsymbol{\epsilon}) = 0$.  Using taylor expansion, we have

$$
g(\mathbf{x}+\boldsymbol{\epsilon}) = g(\mathbf{x}) 
+ \boldsymbol{\epsilon}^{\mathsf {T}} \nabla f(\mathbf{x}) + O(|\boldsymbol{\epsilon}|^2)
$$

In the limit $\|\boldsymbol{\epsilon}\| \rightarrow 0$, $\boldsymbol{\epsilon}$ represents a tangent vector on the surface at $\mathbf{x}$, 
and satisfies $\boldsymbol{\epsilon}^{\mathsf {T}} \nabla f(\mathbf{x}) = 0$.

To find a stationary point $\mathbf{x}^{*}$,
we move $\mathbf{x}$ along the surface towards the direction of the projection of $\nabla f(\mathbf{x})$, 
since such direction always increase the value of $f(\mathbf{x})$. 
Until $\nabla f(\mathbf{x})$ is also orthogonal to the surface, we obtain a stationary point that satisfies

$$
\nabla f(\mathbf{x}) + \lambda \nabla g(\mathbf{x}) = 0
$$

where $\lambda$ is called the Lagrange multiplier.

Therefore, the equivalent problem is to maximize the Lagrangian function without constraints

$$
L(\mathbf{x}, \lambda) = f(\mathbf{x}) + \lambda g(\mathbf{x})
$$

Now consider maximize $f(\mathbf{x})$ under the inequality constraint $g(\mathbf{x}) \ge 0$.

If the stationary point lies on the constraint surface, where the constraint is said to be **active**,
the solution will be the same as maximizing $f(\mathbf{x})$ with the equality constraint $g(\mathbf{x}) = 0$, from which we get the stationary condition $\nabla f(\mathbf{x}) + \lambda\nabla g(\mathbf{x}) = 0$.
However, we require that the gradient at the stationary point $\nabla f(\mathbf{x}^\ast)$ points to region $g(\mathbf{x}) < 0$.
Otherwise, by moving $\mathbf{x}$ into the region we increase value of $f(\mathbf{x})$. 
Since $\nabla g(\mathbf{x})$ always points to the direction where $g(\mathbf{x})$ increases, $\nabla f(\mathbf{x})$ and $\nabla g(\mathbf{x})$ are anti-parallel and $\lambda > 0$.

If the stationary point lies inside the region, where the constrain is said to be inactive,
the constraint does not have any effect. The solution is the same as the problem of maximizing $f(\mathbf{x})$ without constrain.

Therefore, the problem is equivalent to maximize

$$
L(\mathbf{x}, \lambda) = f(\mathbf{x}) + \lambda g(\mathbf{x})
$$

in two separate cases

$$
\lambda = 0, g(x) \ge 0 \quad \text{or} \quad \lambda > 0, g(x) = 0
$$

which is equivalently given by the **KKT conditions**:

$$
\begin{align*}
g(\mathbf{x}) &\ge 0 \\
\lambda &\ge 0 \\
\lambda g(\mathbf{x}) &= 0 \\
\end{align*}
$$

Note that to minimize $f(\mathbf{x})$, we can simply maximize the $-f(\mathbf{x})$. Or equivalently, we minimize

$$
L(\mathbf{x}, \lambda) = f(\mathbf{x}) - \lambda g(\mathbf{x})
$$

with condition

$$
\begin{align*}
g(\mathbf{x}) &\ge 0 \\
\lambda &\ge 0 \\
\lambda g(\mathbf{x}) &= 0 \\
\end{align*}
$$

### Duality

Reference:

- Lagrangian Duality for Dummies. David Knowles.

Consider a optimization problem:

$$
\begin{align*}
\text{minimize} &\quad f_0(x) \\
\text{subject to} &\quad f_i(x) \le 0, \quad i = 1, \dots, m\\
\end{align*}
$$

For simplicity, equality constraints do not appear but are strainforward to take into account.

An equivelant unconstrained problem is to minimize the error function

$$
J(x) = f_0(x) + \sum_i I(f_i(x)) 
$$

in which $I$ is an indicator function given by

$$
I(u) = \begin{cases}
0 & \text{ if } u\le 0 \\
\infty & \text{otherwise} \\
\end{cases}
$$

This function gives a infinity penalty to any unsatisfied constraint and has no effect for
the rest.
Despite simplicity, it is impractical to solve since the error function is now discontinuous.

So we consider a 'softer' option given by $\lambda\_i f\_i(x)$. For $\lambda\_i > 0$,
it indeed gives postive penelty to unsatisfied constraints.
This gives rise to the Lagragian function

$$
L(x, \lambda) = f_0(x) + \sum_{i=1}^M \lambda_i f_i(x)
$$

For a specific $x$, if $f\_i(x) < 0$, the constraint should have no effect so we set $\lambda\_i = 0$.
If $f\_i(x) > 0$, we take $\lambda\_i \rightarrow \infty$ which gives a infinite panelty.
Therefore, we see

$$
\max_{\lambda} L(x, \lambda) = J(x)
$$

under the constraint $\lambda\_i \ge 0$ for $i=1, \dots, m$.

And the optimization problem becomes

$$
\min_{x} \max_{\lambda} L(x, \lambda)
$$

This form of problem is sometimes intractable. However, if we convert it into another form given by

$$
\max_{\lambda} \min_{x} L(x, \lambda) = \max_{\lambda} g(\lambda)
$$

where $g(\lambda) = \min\_{x} L(x, \lambda)$ is called the **dual function**,
we obtain a good property that wether $f\_0(x)$ is convex or not, $g(\lambda)$ is always concave,
since $g(\lambda)$ is a pointwise minimum of affine functions (i.e. $L$ is linear in $\lambda$).
Maximization of $g(\lambda)$ is known as the **dual problem**, and the original problem is the **primal problem**.

Now we show the relationship between solutions of two problems. Since $\lambda u$ is a lower bound of $I(u)$, for all $\lambda \ge 0$, we have

$$
\begin{align*}
& & L(x, \lambda) &\le J(x) \\
&\Rightarrow & \min_x L(x, \lambda) &\le \min_x J(x) \\
&\Rightarrow & d^\ast = \max_\lambda \min_x L(x, \lambda) &\le \min_{x} \max_{\lambda} L(x, \lambda) = p^\ast \\
\end{align*}
$$

where $d^\ast$ and $p^\ast$ are the optima of the dual problem and primal problem respectively.
This property is known as the weak duality, since $d^\ast$ gives a tight lower bound of $p^\ast$.
The difference $p^\ast - d^\ast$ is called the **optimal duality gap**. For strong duality, it takes $0$.

It can be shown that the strong duality holds if the primal problem is convex and
a feasible point (i.e. a point that satisfies all constraints) exists.

